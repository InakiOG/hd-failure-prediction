{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a9b1fde",
   "metadata": {},
   "source": [
    "# LSTM + Decision Tree Integration Demo\n",
    "\n",
    "This notebook demonstrates a full pipeline for hard drive failure prediction using both LSTM (deep learning) and Decision Tree (CT) models.\n",
    "\n",
    "You will:\n",
    "- Train and test the LSTM model\n",
    "- Train and test the Decision Tree model on raw data\n",
    "- Generate LSTM predictions for all drives\n",
    "- Test a random drive using the LSTM model\n",
    "- Feed the LSTM results into the Decision Tree and analyze the outcome\n",
    "\n",
    "**Requirements:**  \n",
    "- All dependencies installed (see `requirements.txt`)\n",
    "- Data available in `../../data/data_Q1_2025/`\n",
    "- LSTM and CT code available in `notebooks/LSTM/smart.py` and `notebooks/CT/CT.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0aa69b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Setup and Imports\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from typing import Optional\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# Add project root and submodules to sys.path for imports\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "sys.path.append(project_root)\n",
    "sys.path.append(os.path.join(project_root, \"notebooks/LSTM\"))\n",
    "sys.path.append(os.path.join(project_root, \"notebooks/CT\"))\n",
    "\n",
    "import notebooks.LSTM.smart as smart\n",
    "import notebooks.CT.CT as CT\n",
    "\n",
    "# Set device for torch: use GPU if available, else CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8120ba31",
   "metadata": {},
   "source": [
    "## Step 2: Train and Test the LSTM Model\n",
    "\n",
    "We will train the LSTM model.\n",
    "If a trained model already exists, this step will load it instead of retraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae4b4a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LSTM model already exists at f:\\Github\\hd-failure-prediction\\models/LSTM/lstm_model.joblib\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "lstm_model_path = os.path.join(project_root, \"models/LSTM/lstm_model.joblib\")\n",
    "lstm_data_path = os.path.join(project_root, \"data/data_Q1_2025\")\n",
    "lstm_output_dir = os.path.join(os.getcwd(), \"lstm_demo_output\")\n",
    "\n",
    "# Train or load the LSTM model\n",
    "if os.path.exists(lstm_model_path) or os.path.exists(lstm_model_path.replace('.joblib', '.pth')):\n",
    "    print(f\"✅ LSTM model already exists at {lstm_model_path}\")\n",
    "else:\n",
    "    print(\"Training LSTM model...\")\n",
    "    # You may need to adjust parameters as needed\n",
    "    if hasattr(smart, \"train_lstm_model\"):\n",
    "        smart.train_lstm_model(\n",
    "            data_path=lstm_data_path,\n",
    "            model_path=lstm_model_path,\n",
    "            output_dir=lstm_output_dir,\n",
    "            epochs=5  # Adjust as needed for demo\n",
    "        )\n",
    "        print(\"✅ LSTM model training complete.\")\n",
    "    else:\n",
    "        print(\"❌ train_lstm_model function not found in smart.py. Please train the model manually.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db043487",
   "metadata": {},
   "source": [
    "## Step 3: Evaluate LSTM Model on Test Set\n",
    "\n",
    "Let's evaluate the LSTM model's performance on the test set and display some metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5297ee82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Complete model loaded from f:\\Github\\hd-failure-prediction\\models/LSTM/lstm_model.joblib\n",
      "joblib load failed with UnicodeDecodeError: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte\n",
      "✅ Complete model loaded from f:\\Github\\hd-failure-prediction\\models/LSTM/lstm_model.joblib\n",
      "✅ Model metrics loaded from f:\\Github\\hd-failure-prediction\\models/LSTM/lstm_model_metrics.json\n",
      "Previous best validation loss: 59515.34847878398\n",
      "Trained model found! Loading and testing...\n",
      "Testing loaded model...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m num_test_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting loaded model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m test_pbar \u001b[38;5;241m=\u001b[39m tqdm(\u001b[43mtest_loader\u001b[49m, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting Model\u001b[39m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m test_data, test_labels \u001b[38;5;129;01min\u001b[39;00m test_pbar:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# Try loading the full model with joblib first\n",
    "try:\n",
    "    model, model_metrics = smart.load_model(lstm_model_path, device, load_whole_model=True)\n",
    "except UnicodeDecodeError as e:\n",
    "    print(f\"joblib load failed with UnicodeDecodeError: {e}\")\n",
    "    # Try loading as a PyTorch model if joblib fails\n",
    "    model, model_metrics = smart.load_model(lstm_model_path.replace('.joblib', '.pth'), device, load_whole_model=True)\n",
    "\n",
    "minimum_loss = np.inf\n",
    "if model_metrics:\n",
    "    print(f\"Previous best validation loss: {model_metrics.get('val_loss', 'N/A')}\")\n",
    "    minimum_loss = model_metrics.get('val_loss', minimum_loss)\n",
    "print(\"Trained model found! Loading and testing...\")\n",
    "\n",
    "# Test the loaded model\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "num_test_batches = 0\n",
    "\n",
    "print(\"Testing loaded model...\")\n",
    "test_pbar = tqdm(test_loader, desc=\"Testing Model\", leave=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_data, test_labels in test_pbar:\n",
    "        test_data, test_labels = test_data.to(device), test_labels.to(device)\n",
    "        predictions = model(test_data)\n",
    "        loss = loss_function(predictions, test_labels)\n",
    "        \n",
    "        test_loss += loss.item()\n",
    "        num_test_batches += 1\n",
    "        \n",
    "        test_pbar.set_postfix({'Test Loss': f'{loss.item():.6f}'})\n",
    "\n",
    "avg_test_loss = test_loss / num_test_batches if num_test_batches > 0 else 0\n",
    "print(f\"Model Test Results - Average Loss: {avg_test_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3c63c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test the loaded model\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "num_test_batches = 0\n",
    "\n",
    "print(\"Testing loaded model...\")\n",
    "test_pbar = tqdm(test_loader, desc=\"Testing Model\", leave=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_data, test_labels in test_pbar:\n",
    "        test_data, test_labels = test_data.to(device), test_labels.to(device)\n",
    "        predictions = model(test_data)\n",
    "        loss = loss_function(predictions, test_labels)\n",
    "        \n",
    "        test_loss += loss.item()\n",
    "        num_test_batches += 1\n",
    "        \n",
    "        test_pbar.set_postfix({'Test Loss': f'{loss.item():.6f}'})\n",
    "\n",
    "avg_test_loss = test_loss / num_test_batches if num_test_batches > 0 else 0\n",
    "print(f\"Model Test Results - Average Loss: {avg_test_loss:.6f}\")\n",
    "\n",
    "\n",
    "# Generate predictions on test set\n",
    "model.eval()\n",
    "test_predictions = []\n",
    "test_targets = []\n",
    "\n",
    "print(\"Generating final predictions...\")\n",
    "with torch.no_grad():\n",
    "    for test_data, test_labels in tqdm(test_loader, desc=\"Generating predictions\"):\n",
    "        test_data, test_labels = test_data.to(device), test_labels.to(device)\n",
    "        predictions = model(test_data)\n",
    "        test_predictions.append(predictions.cpu().numpy())\n",
    "        test_targets.append(test_labels.cpu().numpy())\n",
    "        \n",
    "# Concatenate all predictions and targets\n",
    "test_predictions = np.concatenate(test_predictions, axis=0)\n",
    "test_targets = np.concatenate(test_targets, axis=0)\n",
    "\n",
    "# Plot predictions vs actual values for the first feature\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "# Plot first few samples for visualization\n",
    "num_samples_to_plot = min(50, len(test_predictions))\n",
    "x = np.arange(num_samples_to_plot)\n",
    "\n",
    "ax1.plot(x, test_predictions[:num_samples_to_plot, 0, 0], label='Predicted', alpha=0.7)\n",
    "ax1.plot(x, test_targets[:num_samples_to_plot, 0, 0], label='Actual', alpha=0.7)\n",
    "ax1.set_xlabel(\"Sample\")\n",
    "ax1.set_ylabel(\"Feature 1 Value\")\n",
    "ax1.set_title(\"Predictions vs Actual Values (Feature 1)\")\n",
    "ax1.legend()\n",
    "\n",
    "# Plot prediction error\n",
    "error = test_predictions[:num_samples_to_plot, 0, 0] - test_targets[:num_samples_to_plot, 0, 0]\n",
    "ax2.plot(x, error, label='Prediction Error', color='red', alpha=0.7)\n",
    "ax2.set_xlabel(\"Sample\")\n",
    "ax2.set_ylabel(\"Error\")\n",
    "ax2.set_title(\"Prediction Error\")\n",
    "ax2.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ffe979",
   "metadata": {},
   "source": [
    "## Step 4: Train and Test the Decision Tree (CT) on Raw Data\n",
    "\n",
    "We will now train and test the Decision Tree model using the raw SMART data, without LSTM features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25866fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔬 Starting CT analysis of LSTM predictions...\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "stat: path should be string, bytes, os.PathLike or integer, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m ct_data_path \u001b[38;5;241m=\u001b[39m lstm_data_path  \u001b[38;5;66;03m# Use the same data as LSTM\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# The CT pipeline expects a features file. For raw SMART, set feature_selection_method='smart_only'\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m ct_results \u001b[38;5;241m=\u001b[39m \u001b[43mCT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalyze_lstm_predictions_with_ct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlstm_features_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# None means use raw data\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mground_truth_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mct_data_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_selection_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msmart_only\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Only use SMART features\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mct_raw_analysis\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCT Results on Raw Data:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(ct_results)\n",
      "File \u001b[1;32mf:\\Github\\hd-failure-prediction\\notebooks\\CT\\CT.py:701\u001b[0m, in \u001b[0;36manalyze_lstm_predictions_with_ct\u001b[1;34m(lstm_features_path, ground_truth_path, feature_selection_method, output_dir)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m60\u001b[39m)\n\u001b[0;32m    700\u001b[0m \u001b[38;5;66;03m# Load LSTM features\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m lstm_features_df \u001b[38;5;241m=\u001b[39m \u001b[43mload_lstm_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlstm_features_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lstm_features_df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mf:\\Github\\hd-failure-prediction\\notebooks\\CT\\CT.py:588\u001b[0m, in \u001b[0;36mload_lstm_predictions\u001b[1;34m(lstm_features_path)\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_lstm_predictions\u001b[39m(lstm_features_path):\n\u001b[0;32m    579\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    580\u001b[0m \u001b[38;5;124;03m    Load LSTM predictions from CSV file generated by smart.py\u001b[39;00m\n\u001b[0;32m    581\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    586\u001b[0m \u001b[38;5;124;03m        pd.DataFrame: DataFrame with LSTM features for CT analysis\u001b[39;00m\n\u001b[0;32m    587\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 588\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlstm_features_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    589\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m❌ LSTM features file not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlstm_features_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    590\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Green\\miniconda3\\envs\\thesis\\lib\\genericpath.py:19\u001b[0m, in \u001b[0;36mexists\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 19\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: stat: path should be string, bytes, os.PathLike or integer, not NoneType"
     ]
    }
   ],
   "source": [
    "# Run standard CT analysis on raw data\n",
    "ct_data_path = lstm_data_path  # Use the same data as LSTM\n",
    "\n",
    "# The CT pipeline expects a features file. For raw SMART, set feature_selection_method='smart_only'\n",
    "ct_results = CT.analyze_lstm_predictions_with_ct(\n",
    "    lstm_features_path=None,  # None means use raw data\n",
    "    ground_truth_path=ct_data_path,\n",
    "    feature_selection_method='smart_only',  # Only use SMART features\n",
    "    output_dir=\"ct_raw_analysis\"\n",
    ")\n",
    "print(\"CT Results on Raw Data:\")\n",
    "print(ct_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0431f5a",
   "metadata": {},
   "source": [
    "## Step 5: Generate LSTM Predictions for All Drives\n",
    "\n",
    "We will use the trained LSTM model to generate predictions for all drives, and export features for CT analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcbc299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate LSTM predictions and export features for CT\n",
    "ct_features_output_dir = \"ct_lstm_features\"\n",
    "if hasattr(smart, \"export_for_ct_analysis\"):\n",
    "    predictions_df, ct_features_df = smart.export_for_ct_analysis(\n",
    "        model_path=lstm_model_path,\n",
    "        dataset_path=lstm_data_path,\n",
    "        output_dir=ct_features_output_dir\n",
    "    )\n",
    "    print(f\"Exported {len(ct_features_df)} drive-level features for CT analysis.\")\n",
    "else:\n",
    "    print(\"❌ export_for_ct_analysis function not found in smart.py. Please generate LSTM features manually.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabe1e4a",
   "metadata": {},
   "source": [
    "## Step 6: Test a Random Drive with the LSTM Model\n",
    "\n",
    "Let's select a random drive from the dataset, run it through the LSTM model, and display the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715fb195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the list of drives\n",
    "all_serials = []\n",
    "for f in os.listdir(lstm_data_path):\n",
    "    if f.endswith('.csv'):\n",
    "        try:\n",
    "            df = pd.read_csv(os.path.join(lstm_data_path, f), usecols=['serial_number'])\n",
    "            all_serials.extend(df['serial_number'].unique())\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {f}: {e}\")\n",
    "all_drives = list(set(all_serials))\n",
    "random_drive = random.choice(all_drives)\n",
    "print(f\"Randomly selected drive: {random_drive}\")\n",
    "\n",
    "# Run the LSTM model on this drive (assuming such a function exists)\n",
    "if hasattr(smart, \"predict_drive\"):\n",
    "    random_drive_pred = smart.predict_drive(\n",
    "        model_path=lstm_model_path,\n",
    "        drive_serial=random_drive,\n",
    "        data_path=lstm_data_path\n",
    "    )\n",
    "    print(f\"LSTM prediction for drive {random_drive}: {random_drive_pred}\")\n",
    "else:\n",
    "    print(\"❌ predict_drive function not found in smart.py. Please test a drive manually.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c245e22",
   "metadata": {},
   "source": [
    "## Step 7: Feed LSTM Results into the Decision Tree (CT)\n",
    "\n",
    "Now, we will use the LSTM-generated features as input to the Decision Tree model and analyze the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d494c21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the exported LSTM features for CT\n",
    "lstm_features_path = os.path.join(ct_features_output_dir, \"ct_features.csv\")\n",
    "\n",
    "# Run CT analysis on LSTM features\n",
    "ct_lstm_results = CT.analyze_lstm_predictions_with_ct(\n",
    "    lstm_features_path=lstm_features_path,\n",
    "    ground_truth_path=lstm_data_path,\n",
    "    feature_selection_method='all',  # Use all features (LSTM + SMART)\n",
    "    output_dir=\"ct_lstm_analysis\"\n",
    ")\n",
    "print(\"CT Results on LSTM Features:\")\n",
    "print(ct_lstm_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894965d7",
   "metadata": {},
   "source": [
    "## Step 8: Visualize and Interpret Results\n",
    "\n",
    "Let's visualize the feature importance and summarize the pipeline's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7f4452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load feature importance from CT results\n",
    "importance_df = pd.DataFrame(ct_lstm_results['feature_importance'])\n",
    "top_features = importance_df.sort_values('gini_importance', ascending=False).head(10)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(top_features['feature'], top_features['gini_importance'])\n",
    "plt.xlabel('Gini Importance')\n",
    "plt.title('Top 10 Most Important Features (LSTM + SMART)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "\n",
    "print(\"Pipeline complete! You have now trained, tested, and integrated LSTM and Decision Tree models for hard drive failure prediction.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
